## spark出现的原因：
- 迭代式的算法
- 迭代式的数据挖掘工具
    - 同一个数据集上的adhoc queries

## RDD支持
- 运算的中间结果持久化在内存里
- 通过控制分区来优化数据存放
- 用丰富的operator来处理数据


# spark的应用

spark从硬盘中加载数据时，一个node只加载本机硬盘上的数据。\
在计算过程中，如果内存中有数据，先计算内存中的数据，运行backup task夹杂硬盘中的数据。如果内存中没有数据，先加载硬盘中的数据，一边加载一边计算，中间结果存放在内存中，最终结果传递给driver node，释放内存。\
\
因此，spark的应用场景是——需要对中间结果再进行多次计算的算法（迭代算法），这样中间结果一直都是在内存里，无需从硬盘中加载，节省了大量时间。\
\
在进行迭代计算的情况下，与MapReduce的对比：MapReduce的中间结果要存放到硬盘中，如果对中间结果进行多次迭代计算，那么每一次计算都需要从硬盘中加载数据，浪费了很多的I/O时间。

