# 整体架构

![](http://ww1.sinaimg.cn/large/005N2p5vly1fqz2qyyce9j311y0ii40y.jpg)

# 提供的服务

- Hadoop发行版：适应海量数据持续增长，提供容错性保障。
- 分析型数据库：以批处理方式提供高性能分析，广泛应用于数据仓库和数据集市的构建。
- NewSQL数据库：可处理结构和非结构化数据，响应高并发请求，实现毫秒级精确查询。
- 实时计算引擎：多功能流数据计算平台，适应低延时和高吞吐双场景。
- 数据挖掘平台：分布式机器学习平台，内置丰富的算法库与行业应用模块。
- 图形化运维与管理：图形化的集群控制中心，提供按钮式与可视化的服务与机器管理。
- 报表与调度工具：多种高效轻便的开发工具，流畅实现大数据完整开发过程。
- 在线应用市场：上架丰富的大数据服务，支持一键在线安装、升级。


# 星环构建的企业级Hadoop/Spark分析平台

### Spark自身存在的缺陷（来自星环的2014年的文档，Spark已经更新了很多版本，可能不适用现在的情况。不过可以参考一下）

1. **稳定性方面**，由于代码质量问题，Spark长时间运行会经常出错，在架构方面，由于大量数据被缓存在内存中，Java垃圾回收缓慢的现象严重，导致Spark的性能不稳定，在复杂场景SQL的性能甚至不如现有的Map/Reduce。
2. **不能处理大数据**，单台机器处理数据过大，或者由于数据倾斜导致中间结果超过内存大小时，常常出现内存不够或者无法运行得出结果。然而，Map/Reduce计算框架可以处理大数据，在这方面，Spark不如Map/Reduce计算框架有效。
3. **不能支持复杂的SQL统计**，目前Spark支持的SQL语法的完整程度还不能应用在复杂数据分析中。
4. **在可管理性方面，Spark与YARN的结合不完善**，这就在用户使用过程中埋下隐患，易出现各种难题。

### 分析——星环文档中有价值的信息

1. **Spark确实存在GC回收缓慢的现象**——这是因为Spark底层是基于Java jvm的，采用了jvm的GC机制。**Alluxio的原理就是**：当计算层有着较为严重的内存资源、以及JVM GC压力，或者较高的任务失败率时，Alluxio作为输入输出数据的Off heap存储可以极大缓解这一压力，并使计算消耗的时间和资源更可控可预测。


2. 关于SQL语法支持这里，截止现在（2018.5）Spark已经更新了很多版本，暂未调研Spark SQL，可能已经更新的很完善了
3. Spark与YARN的结合——文档过旧，不能判断现在yarn的支持状况。有些公司开始采用Mesos进行资源的管理、调度，需要进一步调研yarn、mesos的发展状况。（Spark和Mesos都出自伯克利大学的AMPLab，目测mesos会好一点）

# Transwarp Inceptor对Spark进行的改进















