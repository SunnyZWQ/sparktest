# 整体架构

![](http://ww1.sinaimg.cn/large/005N2p5vly1fqzc79q55yj31if0qnn1j.jpg)

# 提供的服务

- Hadoop发行版：适应海量数据持续增长，提供容错性保障。
- 分析型数据库：以批处理方式提供高性能分析，广泛应用于数据仓库和数据集市的构建。
- NewSQL数据库：可处理结构和非结构化数据，响应高并发请求，实现毫秒级精确查询。
- 实时计算引擎：多功能流数据计算平台，适应低延时和高吞吐双场景。
- 数据挖掘平台：分布式机器学习平台，内置丰富的算法库与行业应用模块。
- 图形化运维与管理：图形化的集群控制中心，提供按钮式与可视化的服务与机器管理。
- 报表与调度工具：多种高效轻便的开发工具，流畅实现大数据完整开发过程。
- 在线应用市场：上架丰富的大数据服务，支持一键在线安装、升级。


Transwarp基于Apache Hadoop 2.7.2开发,以HDFS为文件系统,以YARN为资源管理平台。


# 星环构建的企业级Hadoop/Spark分析平台

### Spark自身存在的缺陷（来自星环的2014年的文档，Spark已经更新了很多版本，可能不适用现在的情况。不过可以参考一下）

1. **稳定性方面**，由于代码质量问题，Spark长时间运行会经常出错，在架构方面，由于大量数据被缓存在内存中，Java垃圾回收缓慢的现象严重，导致Spark的性能不稳定，在复杂场景SQL的性能甚至不如现有的Map/Reduce。
2. **不能处理大数据**，单台机器处理数据过大，或者由于数据倾斜导致中间结果超过内存大小时，常常出现内存不够或者无法运行得出结果。然而，Map/Reduce计算框架可以处理大数据，在这方面，Spark不如Map/Reduce计算框架有效。
3. **不能支持复杂的SQL统计**，目前Spark支持的SQL语法的完整程度还不能应用在复杂数据分析中。
4. **在可管理性方面，Spark与YARN的结合不完善**，这就在用户使用过程中埋下隐患，易出现各种难题。

### 分析——星环文档中有价值的信息

1. **Spark确实存在GC回收缓慢的现象**——这是因为Spark底层是基于Java jvm的，采用了jvm的GC机制。


2. 关于SQL语法支持这里，截止现在（2018.5）Spark已经更新了很多版本，暂未调研Spark SQL，可能已经更新的很完善了
3. Spark与YARN的结合——文档过旧，不能判断现在yarn的支持状况。有些公司开始采用Mesos进行资源的管理、调度，需要进一步调研yarn、mesos的发展状况。（Spark和Mesos都出自伯克利大学的AMPLab，mesos可能会支持的更好一点，还需要进一步调研）

# Transwarp Inceptor对Spark进行的改进

### 高性能

- 首先，支持高性能Apache Spark作为缺省执行引擎，可比原生的Hadoop Map/Reduce快；

- 其次，通过建立独立于Spark的分布式列式缓存层，可以有效防止GC的影响，消除Spark的性能波动，同时在列式缓存上实现索引机制，进一步提高了执行性能；

    >**Alluxio的原理是**：当计算层有着较为严重的内存资源、以及JVM GC压力，或者较高的任务失败率时，Alluxio作为输入输出数据的Off heap存储可以极大缓解这一压力，并使计算消耗的时间和资源更可控可预测。

    >Alluxio在缓存时，可以采用分层存储策略（内存、SSD和磁盘多种存储资源）\
    通过Alluxio提供的LRU、LFU等缓存策略可以保证热数据一直保留在内存中，冷数据则被持久化到level 2甚至level 3的存储设备上；而HDFS作为长期的文件备份系统。

    - **【分析】星环采用了和Alluxio一样的思想，不过Alluxio只是采用了内存存储的策略，将底层存储加载到内存，具体的存储形式取决于底层存储（Alluxio在实验功能里支持key-value存储）。猜测——星环采用了Redis数据库作为缓存层，Alluxio于2013年发布，星环在2014年写出这篇架构文章，很可能是采用了Alluxio的思想，但当时Alluxio并不完善，因此星环自己直接采用了Redis作为缓存层）**
    - **【分析】星环的缓存层采用的存储介质是SSD，星环在文章中说过——经过测评，发现在内存中缓存和在SSD中进行缓存，性能没有明显下降，但可以用同样的价格买到容量大十倍的SSD作为缓存，一方面可以提供跟纯内存缓存接近的功能，一方面也可比纯内存数据库处理更大的数据**
    - **【分析】Alluxio可以采用分层策略，因此我们的大数据平台可以采用Alluxio，并将缓存级别设置为：内存-->SSD-->硬盘等其他存储介质**

![](http://ww1.sinaimg.cn/large/005N2p5vly1fqz5vwwcpij30iw08a788.jpg)


- 再次，在SQL执行计划优化方面，实现了基于代价的优化器（cost based optimizer）以及多种优化策略，性能可以比原生Spark快数倍；最后通过全新的方法解决数据倾斜或者数据量过大的问题，使得处理超大数据量时也游刃有余。


# 星环实时系统的架构设计

#### 常用lambda架构图
![](http://ww1.sinaimg.cn/large/005N2p5vgy1fqzbanp7jtj30hb05dq34.jpg)

#### 常用Kappa架构图
![](http://ww1.sinaimg.cn/large/005N2p5vgy1fqzbbbglnjj30h604mjrj.jpg)


>通常Lambda的实现方案是，数据进入分布式实时队列Kafka，Hadoop作为Batch Layer执行实时性需求不高的历史数据分析生成历史视图，Storm作为Speed Layer负责实时数据处理生成实时视图，二者结果的同一归宿是Druid，由它向用户提供交互式实时查询。

>但是Lambda架构有着自身难以避免的弊端，首先做实时查询时只能进行预先设定的分析，不能做Ad-Hoc分析；其次，用户需要维护跑在两套系统中的两套代码，不方便代码调试和参数调优；最后从开发、测试和运维的角度来看，在架构中部署两套系统的方式也是不利的。为此，前LinkedIn大神Jay Kreps设计了Kappa架构解决了Lambda中存在的问题。

Kappa方案的诞生归功于Spark的发展，由于Spark对于批处理和流计算双方面的支持，使两套系统的合并成为可能。Kappa中实时计算和批处理过程可使用同一份代码，极大的方便了代码优化、模型验证工作。下图是实现Kappa的一种常用方案，其中存在一个问题，Kafka最多只能存储近30天的历史数据，对于数据规模较大的情况此结构将力不从心。


星环选择了Kappa架构来构建实时系统，并对其做了一些改进。首先我们使用一款对SQL和PL/SQL支持能力很高的产品StreamSQL作为中间的批&流处理系统，并在原有设计结构的基础上增加了Holodesk存储引擎，用来存放经过行列转换过的StreamSQL的结果，Holodesk可以将之保留任意长时间，甚至永久保留，并可供Inceptor来日做分析。


#### 星环优化后的Kappa结构

![](http://ww1.sinaimg.cn/large/005N2p5vly1fqzc5gu2zlj30iy07imxh.jpg)


# 容器技术和Kubernetes资源管理
TDH中的组件都针对Docker作了优化,计算引擎也可以使用Kubernetes进行资源管理,得以使TDH以较低 的成本部署在公共云或者私有云上。星环还充分利用Docker和Kubernetes的资源隔离能力和对资源调度的QoS 支持,提供了弹性的资源共享,保障数据、资源、应用之间的隔离,实现了更好地多租户管理,以支持各种不 同的业务需求。

容器技术给TDH的部署和维护带来了非常显著的提升,它支持动态扩容、缩容,支持灰度升级,可以实现在 不停服的情况下对系统进行升级。






