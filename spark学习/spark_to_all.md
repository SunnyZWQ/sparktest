## 大数据的实现——分布式

分布式：当进行数据的计算时，将需要处理的数据进行分区，使用**多台电脑并行处理**，这样能极大地缩减数据处理所需要花费的时间。分布式原理也可以应用于数据的存储，原理也是和计算一样，一台电脑的性能不足，所以将数据分片，存储在多台电脑上。

**Hadoop**的出现，使得数据处理与存储能够在多台性能较差的机器上实现。实现了分布式，以及提供了多个满足用户需求的组件。

### 分布式的原理
在一个集群中，有很多个节点（每一台电脑称为一个节点）。这些节点之中有一个Master节点，还有很多个Slave节点。\
Master节点用于资源的分配与管理。\
Slave节点用于数据的计算与存储。

Hadoop中用于计算的组件有两个：

1. MapReduce
2. Spark 

## Spark

简单的定义：Spark是一个高速的、用于分布式的计算系统。

### Spark的原理

- Spark将数据进行并行化处理。
    - 所谓并行化，就是将




----
数据来源：
1. 实时数据
2. 离线数据

\
大数据主要讨论：
1. 计算
    - Spark（离线+实时：Spark Streaming）
    - Storm（实时）
    - MapReduce（离线）

2. 存储
    - HDFS
    - HBase
    - Hive
    - Pig


### Spark 出现的原因 

MapReduce可以进行离线大数据的处理。
- 处理方式单一，只能使用一种模型
- 速度慢（在硬盘上进行处理）。

因此出现了Spark。Spark可以将MapReduce的处理速度提高10-100倍。
- 基于内存计算，中间结果可以保存在内存中，方便下次计算，减少了磁盘I/O
- 对比MapReduce单一的处理方式，Spark可以自定义处理的函数，更灵活。


### 实时处理的技术对比

1. Storm
    - 实时度更高


2. Spark Streaming
    - 处理的数据量更大


Storm与Spark Streaming都是基于内存计算。

但是Storm对实时的处理机制是“事件触发”，有事件就可以触发。Spark Streaming对实时的处理机制是处理一定时间间隔内出现/更新的数据。

Storm可以达到毫秒级的实时计算延迟度，而Spark Streaming只能达到秒级的计算延迟度。

虽然Storm和Spark Streaming都是基于内存计算，但是Storm不支持对计算结果的保存。而Spark Streaming使用的计算原理是Spark core，也就是说能够实现数据的持久化。因此Spark Streaming的吞吐量更大。
































