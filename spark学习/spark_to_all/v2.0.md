# 大数据

1. Volumes——数据量大，PB
2. Variety——类别大，半结构化+非结构化+结构化
3. Velocity——处理速度，在数据量非常庞大的情况下也能做到实时处理
4. Veracity——真实性

>亚马逊网络服务（AWS）、大数据科学家JohnRauser提到一个简单的定义：**大数据就是任何超过了一台计算机处理能力的庞大数据量。**

- 采集
- 存储
- 计算
- 应用
- 决策


# Hadoop

Hadoop的组件

![](http://ww1.sinaimg.cn/large/005N2p5vgy1fq581hbu4fj327q0w0qfs.jpg)

### Hadoop 解决的问题

>所谓Big Data其实是有两部分组成的。一部分是海量运算存储能力，一部分是数据建模算法。\
>第二部分其实是一个蛮久的学科了。20年前我们叫做statistical analysis，10年前叫data mining，5年前叫machine learning，最近叫big data。其实就是用数学建模的方法对过去的数据建模，以期可以预测未来的行为。比如netflix用你的历史评分来猜你喜欢的电影，yelp用你历史喜好来预测你的口味。。。


在没有Hadoop之前，如果人们想在多台计算机上处理数据，首先要将数据分片，分别存储到集群中的每台电脑中，在每台电脑中部署存储、计算环境。接下来要进行数据的计算，需要维护每台机器的数据的计算——包括环境配置、解决并发问题、故障恢复等。

Hadoop解决了并发、分布式（如机器间通信）和故障恢复等计算细节。

总结——Hadoop解决了大数据的可靠存储与计算问题。



### 举个例子——数据的采集

>大数据的采集是指利用多个数据库来接收发自客户端（Web、App或者传感器形式等）的数据，并且用户可以通过这些数据库来进行简单的查询和处理工作。比如，电商会使用传统的关系型数据库MySQL和Oracle等来存储每一笔事务数据，除此之外，Redis和MongoDB这样的NoSQL数据库也常用于数据的采集。在大数据的采集过程中，其主要特点和挑战是并发数高，因为同时有可能会有成千上万的用户来进行访问和操作，比如火车票售票网站和淘宝，它们并发的访问量在峰值时达到上百万，所以需要在采集端部署大量数据库才能支撑。并且如何在这些数据库之间进行负载均衡和分片的确是需要深入的思考和设计。



### Hadoop 是如何解决这两个问题的？

- 存储——HDFS
- 计算——MapReduce

HDFS：解决了分布式的可靠的文件存储问题。具有容错机制——三份备份（可手动设置）

MapReduce：提供了一个编程模型，可在集群上并发地、分布式地处理大量数据集。把并发、分布式（如机器间通信）和故障恢复等计算细节隐藏起来。


# Spark

- [ ] spark core
- [ ] spark streaming
- [ ] Spark 与 MapReduce 对比
- [ ] spark 集成了一整个spark生态系统（core streaming sql mllib graphx）
- [ ] 运行 spark 实例

Spark 也是一个应用于大数据计算的组件。

MapReduce 和 Spark 都是用于计算的组件，但是spark的计算速度比MapReduce要快10x~100x，并且易用性更高。
![](http://ww1.sinaimg.cn/large/005N2p5vgy1fq8p2czl2ij30k008fwhy.jpg)

### Spark 解决的问题

1. 运算速度 

>MapReduce 在计算时将中间结果存放在硬盘中，因此计算时需要不停的从硬盘中加载、存储

Spark在计算时将数据加载到内存中进行计算，并且把中间计算结果也存放在内存中，这样下次使用时直接从内存中读取，就不需要 I/O 开销了。

2. 可以使用自定义函数，没有单一的编程模型的束缚
>MapReduce只提供单一的 Map-Shuffle-Reduce编程模型。这个编程模型的功能非常简单，所以要实现非常复杂的逻辑，就要把这个简单的功能一层一层叠加。因此MapReduce是一种易用性非常非常差的模型。
>易用性差到什么程度——**仅仅实现单表关联就需要非常复杂的逻辑。**






### 为什么 Spark 和 MapReduce 的运算速度差距这么大


### spark 与 MapReduce 对比之 表关联（实例演示）

- MapReduce实现的表关联的代码，以及原理讲解（画图，各个job需要实现的功能）
- Spark实现表关联：
    - spark core 实现 ----> 半结构化+**非结构化**+结构化
    - spark sql 实现 ----> 引出spark的第三个优点：spark 集成了一整个spark生态系统（core、streaming、sql、mllib、graphx）


3. （优点）spark 集成了一整个spark生态系统（core、streaming、sql、mllib、graphx）
>spark的优势不仅体现在性能提升上，spark框架为批处理、交互式、流式、机器学习、图计算提供一个统一的数据处理平台，这相对于使用Hadoop有很大优势。


### Spark Streaming 如何实现实时计算的

Spark进行实时计算的原理是
- 监控一个文件目录，文件里出现的新文件或者是旧文件的更改，都要进行流计算。
- 流计算的具体过程就是将一定时间间隔内的数据形成RDD，再形成RDD流，对流内的每个RDD进行计算。

![](http://ww1.sinaimg.cn/large/005N2p5vly1fq9zh15mfzj30tr06ndgd.jpg)

![](http://ww1.sinaimg.cn/large/005N2p5vly1fq9zgmnoxfj30ub06naah.jpg)

![](http://ww1.sinaimg.cn/large/005N2p5vly1fq9zhg8f59j30ub0as0tr.jpg)

### Spark Streaming 与另一个实时计算框架 Storm 的对比



# 参考


- 什么是大数据？ - 李丽的回答 - 知乎
https://www.zhihu.com/question/23896161/answer/28624675
- 大数据听着很牛，实际上也很牛吗？ - 陈萌萌的回答 - 知乎
https://www.zhihu.com/question/24728633/answer/28781167
- 与 Hadoop 对比，如何看待 Spark 技术？ - 用心阁的回答 - 知乎
https://www.zhihu.com/question/26568496/answer/41608400




# TODO：
- [ ] 搭好ambari
- [ ] 整理好逻辑
- [ ] 加上机器学习、spark SQL 等内容
- [ ] 对每一处细节提出问题，能答疑
- [ ] spark的例子最好能和 MapReduce 对比
- [ ] 讲解spark原理的时候画一张图
- [ ] 根据图讲解spark，输出内容



提交：翻译的功能
    git-amend






