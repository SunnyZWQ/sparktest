参考：http://os.51cto.com/art/201705/541225.htm


# 1 简介
## 1.1 智能运维

智能运维（AIops）：Algorithmic IT operations platforms——基于算法的 IT 运维平台

## 1.2 算法对运维的作用

- 异常检测
- 归因分析

# 2 异常检测

## 2.1 Kale中的skyline模块

Kale是Etsy开源一个内部运维系统，其中的**skyline**部分就是做异常检测的模块。

#### skyline提供的9种异常检测算法

- first_hour_average
- simple_stddev_from_moving_average
- stddev_from_moving_average
- mean_subtraction_cumulation
- least_squares
- histogram_bins
- grubbs
- median_absolute_deviation
- Kolmogorov-Smirnov_test

这九种算法的分类

1. **从正态分布入手**：假设数据服从高斯分布，可以通过标准差来确定绝大多数数据点的区间；或者根据分布的直方图，落在过少直方里的数据就是异常；或者根据箱体图分析来避免造成长尾影响。
2. **从样本校验入手**：采用 Kolmogorov-Smirnov、Shapiro-Wilk、Lilliefor 等非参数校验方法。


#### skyline的缺陷

1. 这里只考虑了一个指标自己的状态，从纵向的时序角度做异常检测。而没有考虑业务的复杂性导致的横向异常。
2. 提供了这么多种算法，到底一个指标在哪种算法下判断的更准？这又是一个很难判断的事情。


问题一：实现上的抉择。同样的样本校验算法，可以用来对比一个指标的当前和历史情况，也可以用来对比多个指标里哪个跟别的指标不一样。

问题二：Skyline 其实自己采用了一种特别朴实和简单的办法来做补充——9 个算法每人一票，投票达到阈值就算数。至于这个阈值，一般算 6 或者 7 这样，即占到大多数即可。


## 2.2 百度SRE的Opprentice

![](http://ww1.sinaimg.cn/large/005N2p5vly1ft72kffw40j30hs0a6wiz.jpg)

#### Opprentice的工作流程

- KPI数据经过各式detector计算得到每个点的诸多feature；
- 通过专门的交互工具，由运维人员标记KPI数据的异常时间段；
- 采用随机森林算法做异常分类。

其中，detector有14种检测方法

![](http://ww1.sinaimg.cn/large/005N2p5vly1ft72qrnm9kj30d70dkk08.jpg)


我们可以看到其中很多算法在 Etsy 的 Skyline 里同样存在。不过，为避免给这么多算法调配参数，直接采用的办法是：每个参数的取值范围均等分一下——反正随机森林不要求什么特征工程。如，用 holt-winters 做为一类 detector。holt-winters 有α，β，γ 三个参数，取值范围都是 [0, 1]。那么它就采样为 (0.2, 0.4, 0.6, 0.8)，也就是 4 ** 3 = 64 个可能。那么每个点就此得到  64  个特征值。


## 2.3 skyline和Opprentice对比

#### 相同之处

先通过不同的统计学算法来尝试发现异常，然后通过一个多数同意的方式/算法来确定最终的判定结果

- Opprentice：随机森林算法
- skyline：开源之后又更新了内部版本Thyme，利用了小波分解、傅里叶变换、Mann-whitney 检测等等技术。
- 社区版本skyline：Earthgecko 利用 Tsfresh 模块来提取时序数据的特征值，以此做多时序之间的异常检测。
    - 后续发展的两种 Skyline，依然都没有使用机器学习，而是进一步深度挖掘和调整时序相关的统计学算法。


## 2.4 其他的时序异常检测算法库

- Yahoo! 在2016年开源的 egads 库。(Java)
- Twitter 在2016年开源的 anomalydetection 库。(R)
- Netflix 在2015年开源的 Surus 库。(Pig，基于PCA)


# 3 归因分析

## 3.1 简介

和异常检测一样，归因分析同样是可以统计学和机器学习方法并行的。

kale系统中的模块
1. skyline——异常检测
2. Oculus——归因分析


## 3.2 Oculus

#### 思路

如果一个监控指标的时间趋势图走势，跟另一个监控指标的趋势图长得比较像，那它们很可能是被同一个根因影响的。那么，如果整体 IT 环境内的时间同步是可靠的，且监控指标的颗粒度比较细的情况下，我们就可能近似的推断：跟一个告警比较像的最早的那个监控指标，应该就是需要重点关注的根因了。

#### 计算方式

- **欧式距离**，就是不同时序数据，在相同时刻做对比。假如0分0秒，a和b相差1000，0分5秒，也相差1000，依次类推。
- **FastDTW**，则加了一层偏移量，0分0秒的a和0分5秒的b相差1000，0分5秒的a和0分10秒的b也相差1000，依次类推。当然，算法在这个简单假设背后，是有很多降低计算复杂度的具体实现的，这里就不谈了。


## 3.3 Granger causality（格兰杰因果关系）

#### 思路

简单来说它通过比较“已知上一时刻所有信息，这一时刻 X 的概率分布情况”和“已知上一时刻除 Y 以外的所有信息，这一时刻 X 的概率分布情况”，来判断 Y 对 X 是否存在因果关系。

可能有了解过一点机器学习信息的读者会很诧异了：不是说机器只能反应相关性，不能反应因果性的么？需要说明一下，这里的因果，是统计学意义上的因果，不是我们通常哲学意义上的因果。

#### 统计学上的因果定义是

在宇宙中所有其他事件的发生情况固定不变的条件下，如果一个事件 A 的发生与不发生对于另一个事件 B 的发生的概率有影响，并且这两个事件在时间上有先后顺序（A前B后），那么我们便可以说 A 是 B 的原因。

## 3.4 皮尔逊系数

其主要元素和采用 FastDTW 算法的 Oculus 类似：correlation 表示相关性的评分、lead/lag 表示不同时序数据在时间轴上的偏移量。

皮尔逊系数在 R 语言里可以特别简单的做到。

其实 R 语言不太适合嵌入到现有的运维系统中。那这时候使用 Elasticsearch 的工程师就有福了。ES 在大家常用的 metric aggregation、bucket aggregation、pipeline aggregation 之外，还提供了一种 matrix aggregation，目前唯一支持的 matrix_stats 就是采用了皮尔逊系数的计算。




























